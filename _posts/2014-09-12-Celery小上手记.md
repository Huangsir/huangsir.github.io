---
layout: post
title: "Celery小上手记"
description: ""
category: 
tags: []
---

久仰Celery大名，可惜业务上一直是以php为主，即使有需要比较靠谱的常驻内存Server也因并发要求过高使用Golang完成。所以一直无缘上手Celery，只能作为茶余饭后的demo。

但是现在，老夫终于有了一个正当的理由，在项目中使用Celery了贼哈哈哈哈-。-#

Celery的Api文档和Demo程序是相当齐全的，所以初学这，最好直接阅读他的[官方文档](http://www.celeryproject.org/docs-and-support/)。
老夫这里记录的一些老夫在阅读文档时可能没有注意到，最后考反复试验加研读源码找到的入门方案。

首先我们要安装Celery，这个还用说么?  
这里我们使用豆瓣的源，以提高墙内的下载速度。

```bash
pip install celery -i http://pypi.douban.com/simple/
pip install redis -i http://pypi.douban.com/simple/
```

同时，我们还需要用来保存队列数据的broker，这里我们选用[redis](http://redis.io)来保存数据

Ok，所有的工作都准备妥当了，现在我们来到文档Demo的Step1.

首先我们创建一个文件夹叫proj，目录结构大概是：

```bash
proj/__init__.py
    /tasks.py
```

我们在tasks.py里键入代码

```python
#!/usr/bin/env python
# encoding: utf-8

from celery import Celery

app = Celery('tasks', broker='redis://127.0.0.1:6379/0')

@app.task
def add(x, y):
    return x + y
```

然后在proj目录里运行

```bash
celery -A tasks worker -l info
```

就可以跑起来了。  
从`celery --help`里我们可以看到，`-A`是运行一个module的意思，也就是py的文件名。
好了，我们现在已经启动了实例，现在时检验效果的时候。我们在proj目录里再创建一个文件`test.py`

```python
#!/usr/bin/env python
# encoding: utf-8

from tasks import add

if __name__ == '__main__':
    print add(2, 3)
    print add.delay(3, 4)
```

执行后得到结果：

```bash
$ python test.py
$ 5
$ b2382641-0a63-42ca-ac55-1a8c22d5cdec
```

我们看到，直接调用函数也是没有问题的，但是如果用`add.delay`，隔壁shell的celery实例就会输出收到一个task。并且我们的add.delay函数也无法再获得返回值，而是一个uuid的随机字符串。

那假如我们希望能够获得返回值，怎么处理呢？只要这么写就可以了

```python
add.delay(3, 4).get()
```

运行一下， 发现报错了```AttributeError: 'DisabledBackend' object has no attribute '_get_task_meta_for'```

Celery默认就是一个Task Distribute的模式，是不记录返回值的。如果需要Celery将返回值回传给Caller，需要手动指定。详情可以查看文档，老夫没有实验-。-#

完了Step1后，我们进入Step2。Step2里给了一个更高级的用法，不过这里也有老夫一直不理解的地方，如果有哪位大神知道还请不吝赐教。

还是proj这个项目

```
proj/__init__.py
    /celery.py
    /tasks.py
```

proj/celery.py

```python
#!/usr/bin/env python
# encoding: utf-8
from __future__ import absolute_import
from celery import Celery

app = Celery('proj',
             broker='redis://127.0.0.1:6379/0',
             include=['proj.tasks'])

if __name__ == '__main__':
    app.start()
```

proj/tasks.py

```python
#!/usr/bin/env python
# encoding: utf-8
from __future__ import absolute_import
from proj.celery import app

@app.task
def add(x, y):
    return x + y

@app.task
def mul(x, y):
    return x * y

@app.task
def xsum(numbers):
    return sum(numbers)
```

好了，运行一下

```bash
celery -A proj worker -l info
```

报错了```ImportError: No module named proj```，好吧，demo报错了，真是奇怪...   
老夫一开始也被绕进去了，但是后来发现，在`celery.py`里有一句话

```python
include=['proj.tasks']
```

什么概念，就是说引用的module从project开始，但是我们运行的时候已经是在proj目录下了，所以就会报找不到proj的错误。好吧，到proj的上层目录去执行`celery -A proj worker -l info`，果然成功了。

有同学看到，在项目的目录下，有一个`celery.py`，这会和原生的celery module产生冲突，是不建议使用的。so同学们会将这个`celery.py`改成其他名字，比如说像我一样改为`backend.py`

我们再来运行一下。```ImportError: No module named celery``` 又报错了我擦的，说找不到celery。也就是说用这种方式执行的话，目录中一定要有个文件叫`celery.py`
但是这样子又不太符合python里命名文件的规范，总感觉怪怪的。Not good。  
（从老夫的实验来看，Celery的也许就是希望由我们定义一个celery去取代原生的celery实例，但是这东西放在顶层目录，由子module去调用顶层module，在我看来是比较奇怪的一种做法，这也是我所无法理解的地方）

这时我们还有一种方法。

首先我们改一下celery.py这个文件，改为backend.py。同时修改tasks.py里的引用。
这时我们运行一下这个文件

```bash
python backend.py
```

我们发现他输出了和celery一样的结果，也就是说这个文件已经变成了一个celery的文件，所以我们可以直接执行这个文件来达到目的。

我们修改一下目录结构

```
proj/__init__.py
    /backend.py
    apps/__init__.py
        /tasks.py
    lib/__init__.py
        /distribute.py
```

proj/backend.py

```python
#!/usr/bin/env python
# encoding: utf-8
from lib import distribute

app = distribute.app
app.conf.update(
    CELERY_INCLUDE=("apps.tasks",)
)

if __name__ == '__main__':
    app.start()
```

proj/lib/distribute.py

```python
#!/usr/bin/env python
# encoding: utf-8
from celery import Celery

app = Celery('proj',
             broker='redis://127.0.0.1:6379/0')
```

proj/apps/tasks.py

```python
#!/usr/bin/env python
# encoding: utf-8
from lib.distribute import app

@app.task
def add(x, y):
    return x + y

@app.task
def mul(x, y):
    return x * y

@app.task
def xsum(numbers):
    return sum(numbers)
```

好了，这时我们可以运行

```bash
python backend.py worker -l info
```

也是一样的效果。这样就可以避免使用和原装celery相同名字的py文件。

在测试的时候，我被整个文档误导了，我相信应该也会有其他人有和我一样的情况。

假如说我们分有client端和server端，两端的差别很大，是由不同的人员来负责实现的，难道说我们还要在client端布置一遍server端的内容？但是调用的时候又是通过task来调用？无法只提供一个接口的interface就可以随便调用么？

经过老夫反复的实验和仔细阅读celery的源码后，发现不是的，文档上只是一个简写。

还是上面的那段代码，我们增加一个测试目录

```
proj/test/__init__.py
         /apps/__init__.py
             /tasks.py
        /test_by_module.py
        /test_by_name.py
```

proj/test/apps/tasks.py

```python
#!/usr/bin/env python
# encoding: utf-8
from celery import Celery

app = Celery("proj",
             broker="redis://127.0.0.1:6379/0")

@app.task
def add():
    pass

@app.task
def mul():
    pass

@app.task
def xsum():
    pass
```

proj/test/test_by_module.py

```python
#!/usr/bin/env python
# encoding: utf-8

from apps import tasks

if __name__ == '__main__':
    tasks.add.delay(4, 7)
```

proj/test/test_by_name.py

```python
#!/usr/bin/env python
# encoding: utf-8
from celery import Celery

app = Celery("proj", broker="redis://localhost:6379/0")

@app.task(name="apps.tasks.add")
def add():
    pass

@app.task(name="apps.tasks.mul")
def mul():
    pass

@app.task(name="apps.tasks.xsum")
def xsum():
    pass

if __name__ == '__main__':
    mul.delay(4, 7)
```

分别执行test_by_name.py和test_by_module.py

```bash
$ python test_by_module.py
$ 11
$ python test_by_name.py
$ 28
```

我们发现，其实两种方法都是可以的。而文档里的引用估计是为了节省文章，都引用了同一处地方。但是如果在实际运用中，client和server是分开实现的，用这样的方法也是一个不错的选择。

在使用golang，或php时，如果需要调用celery做事，也是以传入string的方式来达到调用目的的。

写到这里，celery的基本server和client的写法都列出来了。剩下的就是在项目中自己组织目录结构，队列结构等。对于老夫来说，除了觉得module之间的引用比较奇怪之外，整个celery还是十分好用的。   
文档的坑基本上就在于此处，再更深度的使用中会有什么更神奇的坑就得老夫慢慢踩完了。

至于一些Router或Chan等高级用法，只能是在不同的项目中case by case的使用了，自己慢慢啃文档去吧。
