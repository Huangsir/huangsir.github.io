---
layout: post
title: "Celery"
description: ""
category: 
tags: []
---

![]({{site.url}}/assets/benefits-of-celery.jpg)

初尝
===

久仰Celery大名，可惜业务上一直是以php为主，即使有需要比较靠谱的常驻内存Server也因并发要求过高使用Golang完成。所以一直无缘上手Celery，只能作为茶余饭后的demo。

但是现在，老夫终于有了一个正当的理由，在项目中使用Celery了贼哈哈哈哈-。-#

Celery的Api文档和Demo程序是相当齐全的，所以初学这，最好直接阅读他的[官方文档](http://www.celeryproject.org/docs-and-support/)。
老夫这里记录的一些老夫在阅读文档时可能没有注意到，最后考反复试验加研读源码找到的入门方案。

首先我们要安装Celery，这个还用说么?  
这里我们使用豆瓣的源，以提高墙内的下载速度。

```bash
pip install celery -i http://pypi.douban.com/simple/
pip install redis -i http://pypi.douban.com/simple/
```

同时，我们还需要用来保存队列数据的broker，这里我们选用[redis](http://redis.io)来保存数据

Ok，所有的工作都准备妥当了，现在我们来到文档Demo的Step1.

首先我们创建一个文件夹叫proj，目录结构大概是：

```bash
proj/__init__.py
    /tasks.py
```

我们在tasks.py里键入代码

```python
#!/usr/bin/env python
# encoding: utf-8

from celery import Celery

app = Celery('tasks', broker='redis://127.0.0.1:6379/0')

@app.task
def add(x, y):
    return x + y
```

然后在proj目录里运行

```bash
celery -A tasks worker -l info
```

就可以跑起来了。  
从`celery --help`里我们可以看到，`-A`是运行一个module的意思，也就是py的文件名。
好了，我们现在已经启动了实例，现在时检验效果的时候。我们在proj目录里再创建一个文件`test.py`

```python
#!/usr/bin/env python
# encoding: utf-8

from tasks import add

if __name__ == '__main__':
    print add(2, 3)
    print add.delay(3, 4)
```

执行后得到结果：

```bash
$ python test.py
$ 5
$ b2382641-0a63-42ca-ac55-1a8c22d5cdec
```

我们看到，直接调用函数也是没有问题的，但是如果用`add.delay`，隔壁shell的celery实例就会输出收到一个task。并且我们的add.delay函数也无法再获得返回值，而是一个uuid的随机字符串。

那假如我们希望能够获得返回值，怎么处理呢？只要这么写就可以了

```python
add.delay(3, 4).get()
```

运行一下， 发现报错了```AttributeError: 'DisabledBackend' object has no attribute '_get_task_meta_for'```

Celery默认就是一个Task Distribute的模式，是不记录返回值的。如果需要Celery将返回值回传给Caller，需要手动指定。详情可以查看文档，老夫没有实验-。-#

完了Step1后，我们进入Step2。Step2里给了一个更高级的用法，不过这里也有老夫一直不理解的地方，如果有哪位大神知道还请不吝赐教。

还是proj这个项目

```
proj/__init__.py
    /celery.py
    /tasks.py
```

proj/celery.py

```python
#!/usr/bin/env python
# encoding: utf-8
from __future__ import absolute_import
from celery import Celery

app = Celery('proj',
             broker='redis://127.0.0.1:6379/0',
             include=['proj.tasks'])

if __name__ == '__main__':
    app.start()
```

proj/tasks.py

```python
#!/usr/bin/env python
# encoding: utf-8
from __future__ import absolute_import
from proj.celery import app

@app.task
def add(x, y):
    return x + y

@app.task
def mul(x, y):
    return x * y

@app.task
def xsum(numbers):
    return sum(numbers)
```

好了，运行一下

```bash
celery -A proj worker -l info
```

报错了```ImportError: No module named proj```，好吧，demo报错了，真是奇怪...   
老夫一开始也被绕进去了，但是后来发现，在`celery.py`里有一句话

```python
include=['proj.tasks']
```

什么概念，就是说引用的module从project开始，但是我们运行的时候已经是在proj目录下了，所以就会报找不到proj的错误。好吧，到proj的上层目录去执行`celery -A proj worker -l info`，果然成功了。

有同学看到，在项目的目录下，有一个`celery.py`，这会和原生的celery module产生冲突，是不建议使用的。so同学们会将这个`celery.py`改成其他名字，比如说像我一样改为`backend.py`

我们再来运行一下。```ImportError: No module named celery``` 又报错了我擦的，说找不到celery。也就是说用这种方式执行的话，目录中一定要有个文件叫`celery.py`
但是这样子又不太符合python里命名文件的规范，总感觉怪怪的。Not good。  
（从老夫的实验来看，Celery的也许就是希望由我们定义一个celery去取代原生的celery实例，但是这东西放在顶层目录，由子module去调用顶层module，在我看来是比较奇怪的一种做法，这也是我所无法理解的地方）

这时我们还有一种方法。

首先我们改一下celery.py这个文件，改为backend.py。同时修改tasks.py里的引用。
这时我们运行一下这个文件

```bash
python backend.py
```

我们发现他输出了和celery一样的结果，也就是说这个文件已经变成了一个celery的文件，所以我们可以直接执行这个文件来达到目的。

我们修改一下目录结构

```
proj/__init__.py
    /backend.py
    apps/__init__.py
        /tasks.py
    lib/__init__.py
        /distribute.py
```

proj/backend.py

```python
#!/usr/bin/env python
# encoding: utf-8
from lib import distribute

app = distribute.app
app.conf.update(
    CELERY_INCLUDE=("apps.tasks",)
)

if __name__ == '__main__':
    app.start()
```

proj/lib/distribute.py

```python
#!/usr/bin/env python
# encoding: utf-8
from celery import Celery

app = Celery('proj',
             broker='redis://127.0.0.1:6379/0')
```

proj/apps/tasks.py

```python
#!/usr/bin/env python
# encoding: utf-8
from lib.distribute import app

@app.task
def add(x, y):
    return x + y

@app.task
def mul(x, y):
    return x * y

@app.task
def xsum(numbers):
    return sum(numbers)
```

好了，这时我们可以运行

```bash
python backend.py worker -l info
```

也是一样的效果。这样就可以避免使用和原装celery相同名字的py文件。

在测试的时候，我被整个文档误导了，我相信应该也会有其他人有和我一样的情况。

假如说我们分有client端和server端，两端的差别很大，是由不同的人员来负责实现的，难道说我们还要在client端布置一遍server端的内容？但是调用的时候又是通过task来调用？无法只提供一个接口的interface就可以随便调用么？

经过老夫反复的实验和仔细阅读celery的源码后，发现不是的，文档上只是一个简写。

还是上面的那段代码，我们增加一个测试目录

```
proj/test/__init__.py
         /apps/__init__.py
             /tasks.py
        /test_by_module.py
        /test_by_name.py
```

proj/test/apps/tasks.py

```python
#!/usr/bin/env python
# encoding: utf-8
from celery import Celery

app = Celery("proj",
             broker="redis://127.0.0.1:6379/0")

@app.task
def add():
    pass

@app.task
def mul():
    pass

@app.task
def xsum():
    pass
```

proj/test/test_by_module.py

```python
#!/usr/bin/env python
# encoding: utf-8

from apps import tasks

if __name__ == '__main__':
    tasks.add.delay(4, 7)
```

proj/test/test_by_name.py

```python
#!/usr/bin/env python
# encoding: utf-8
from celery import Celery

app = Celery("proj", broker="redis://localhost:6379/0")

@app.task(name="apps.tasks.add")
def add():
    pass

@app.task(name="apps.tasks.mul")
def mul():
    pass

@app.task(name="apps.tasks.xsum")
def xsum():
    pass

if __name__ == '__main__':
    mul.delay(4, 7)
```

分别执行test_by_name.py和test_by_module.py

```bash
$ python test_by_module.py
$ 11
$ python test_by_name.py
$ 28
```

我们发现，其实两种方法都是可以的。而文档里的引用估计是为了节省文章，都引用了同一处地方。但是如果在实际运用中，client和server是分开实现的，用这样的方法也是一个不错的选择。

在使用golang，或php时，如果需要调用celery做事，也是以传入string的方式来达到调用目的的。

写到这里，celery的基本server和client的写法都列出来了。剩下的就是在项目中自己组织目录结构，队列结构等。对于老夫来说，除了觉得module之间的引用比较奇怪之外，整个celery还是十分好用的。   
文档的坑基本上就在于此处，再更深度的使用中会有什么更神奇的坑就得老夫慢慢踩完了。

至于一些Router或Chan等高级用法，只能是在不同的项目中case by case的使用了，自己慢慢啃文档去吧。

如何在PHP里调用Celery
===

在php里调用celery可以使用github里提供的一个[开源库](https://github.com/gjedeer/celery-php)，不过老夫是没有使用过，因为老夫使用Redis作为broker，但是github上的这个client似乎并不支持。

这里给出一个最简单的php调用task的demo

```php
<?php
$router = 'celery';#默认的router
$exchange = 'celery';#默认的exchange
$queue = 'celery';#默认的queue
$task = array(
    'task' => 'proj.add',#在celery运行的时候，可以看到所有的task的名称
    'kwargs' => array('x' => 3, 'y' => 4),#参数列表
    'retries' => 0,
    'expire' => null,
);
$task['id'] = sha1(json_encode($task['kwargs']) . time());
$body = array(
    'body' => base64_encode(json_encode($task)),
    'headers' => new stdClass,
    'content-type' => 'application/json',
    'properties' => array(
        'body_encoding' => 'base64',
        'delivery_info' => array(
            'priority' => 0,
            'routing_key' => $router,
            'exchange' => $exchange
        ),
        'delivery_tag' => sha1(base64_encode(json_encode($task)) . time()),
        'delivery_mode' => 2
    ),
    'content-encoding' => 'utf-8'
);
$redis = new Redis();
$redis->pconnect('127.0.0.1', 6379);
$redis->lPush($queue, json_encode($body));
```

不要在意json，相比IO操作，即使用msgpack或者再加上lz4也无法有太多改善，不过对Redis的内存占用是有挺大帮助的，如果你的队列经常大规模拥堵的话-。-#  
当然，如果有人实现了msgpack+lz4或者zip的多语言的broker的话，也请提供到github上，能改善一点是一点哟-。-#

集中式日志(logging)
===

现在，我们需要集中管理Celery的某些日志。比如我们需要将`unregistered task of type`这样的Error集中汇总到syslog或者[sentry](https://github.com/getsentry/sentry)上。  
以sentry为例，首先我们要装好sentry(或者使用在线版)和raven扩展。  
Celery的日志封装得比较严实，而且会劫持代码中的其他logging和print之类的函数，所以用起来比较麻烦。  
但是自动2.2.7之后（之前的我也没用过），提供了两个函数可以用于添加handler。

下面这段函数将注册一个handler到Celery的logger里，这样我们就可以同时handle到`Worker`和`Main Process`的日志

```python
import logging
from raven.handlers.logging import SentryHandler
from celery.signals import after_setup_logger, after_setup_task_logger

@after_setup_logger.connect
@after_setup_task_logger.connect
def after_setup_logger_handler(sender=None, logger=None, loglevel=None, logfile=None, format=None, colorize=None, **kwargs):
    handler = SentryHandler("<your_sentry_client_address>")
    handler.setFormatter(logging.Formatter(logging.BASIC_FORMAT))
    handler.setLevel(logging.ERROR)
    logger.addHandler(handler)
```

以上，这样我们就对`Worker`和`Main Process`都添加全局logging的handler。  
不过值得**注意**的是，不要反复对signal添加handler，否则会受到重复的日志。

现在我们再来运行一下，去看看Sentry里有没有正确的受到log吧。

Links:

* [http://www.toforge.com/2011/06/celery-centralized-logging/](http://www.toforge.com/2011/06/celery-centralized-logging/)


TODO...
